{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AadQNlmVAjJ4"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Asterios7/dlib-wrapper/blob/main/notebooks/examples-colab.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55iF4e35NWKC"
      },
      "source": [
        "# Examples for dlib-wrapper package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR_fO0qiQlTZ"
      },
      "source": [
        "## Notebook prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6w9QYagOpb",
        "outputId": "ab745ae9-ace0-440e-c1f1-8f7e652595ea"
      },
      "outputs": [],
      "source": [
        "# Install the dlib-wrapper package from github\n",
        "!pip install git+https://github.com/Asterios7/dlib-wrapper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avkeiy4gs_NF"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from dlib_wrapper import  dlibFaceProcessor\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox5sTGUgSqwR"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
        "    return np.linalg.norm(vec1 - vec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsTQOG_DhHex",
        "outputId": "b37c148d-871e-4483-a7eb-addd9e7201e0"
      },
      "outputs": [],
      "source": [
        "# Fetch sample images\n",
        "data_path = \"./data\"\n",
        "data_url = \"https://github.com/Asterios7/dlib-wrapper/raw/main/data/data.zip\"\n",
        "\n",
        "if os.path.isdir(data_path):\n",
        "    print(f\"{data_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"{data_path} directory does not exist, creating...\")\n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "\n",
        "    with open('data.zip', 'wb') as f:\n",
        "        print(\"Downloading sample image data...\")\n",
        "        request = requests.get(data_url)\n",
        "        f.write(request.content)\n",
        "\n",
        "    with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping data...\")\n",
        "        zip_ref.extractall(\"data\")\n",
        "        os.remove(\"data.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "EkwqylecsDsB",
        "outputId": "00427bb1-1e43-4889-fa1e-5518ead2d5e1"
      },
      "outputs": [],
      "source": [
        "# Open and plot sample image\n",
        "img = Image.open(\"./data/pulp-fiction.jpg\")\n",
        "img = np.array(img)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Vincent and Jules casually conducting business\")\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34IX7JNqPYet"
      },
      "source": [
        "## Using dlib-wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LvG4JZpqjw_",
        "outputId": "64cde405-56f6-4494-cd7e-c73b8f642e17"
      },
      "outputs": [],
      "source": [
        "# Create a `dlibFaceProcessor` instance\n",
        "face_processor = dlibFaceProcessor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMo5Tw_9y8kC"
      },
      "source": [
        "### Image to face embeddings (option 1)\n",
        "\n",
        "`image` &rarr; `embeddings`\n",
        "\n",
        "Using the `dlibFaceProcessor.detect_and_encode_faces`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogUxVoD9y6M5",
        "outputId": "e7f0281f-f40a-42cc-dc54-cb0513165d4c"
      },
      "outputs": [],
      "source": [
        "# Create face embeddings from image\n",
        "embeddings = face_processor.detect_and_encode_faces(img)\n",
        "print(f\"Number of faces detected: {len(embeddings)}\")\n",
        "print(f\"Number of embeddings per face: {len(embeddings[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQFWAENYdpM"
      },
      "source": [
        "### Image to face embeddings (option 2)\n",
        "\n",
        "`image` &rarr; `boxes` &rarr; `landmarks` &rarr; `aligned_faces` &rarr; `embeddings`\n",
        "\n",
        "Step by step implementation for generating face embeddings. Use this if besides creating the embeddings you also want to:\n",
        "- utilize face landmarks or\n",
        "- extract the faces (aligned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7QuJWsDtbef"
      },
      "outputs": [],
      "source": [
        "# Detect faces, get face boxes\n",
        "boxes = face_processor.detect_faces(img)\n",
        "# Extract face landmarks\n",
        "shapes = face_processor.get_shapes(img, boxes)\n",
        "# Align faces\n",
        "aligned_faces = face_processor.align_faces(img, shapes)\n",
        "# Extract face embeddings\n",
        "embeddings = face_processor.encode_faces(aligned_faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "1NIwPtHC1hbb",
        "outputId": "7c91a92e-aefd-4aa4-d8c2-b962f914493d"
      },
      "outputs": [],
      "source": [
        "# Plot face landmarks\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "ax.imshow(img)\n",
        "for landmarks in shapes:\n",
        "    # Plot landmarks on the face\n",
        "    for n in range(0, 5):  # 5 face landmarks\n",
        "        x = landmarks.part(n).x\n",
        "        y = landmarks.part(n).y\n",
        "        plt.scatter(x, y, color='green', s=5)\n",
        "ax.axis(\"off\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "6mAC6pgArbWL",
        "outputId": "9f1c711c-5bf5-48b1-f1bf-fe0d6719af77"
      },
      "outputs": [],
      "source": [
        "# Plot faces after detection and alignment\n",
        "fig, axes = plt.subplots(1, len(aligned_faces), figsize=(8, 4))\n",
        "for i, face in enumerate(aligned_faces):\n",
        "    axes[i].imshow(face)\n",
        "    axes[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBZyHwR7sojC",
        "outputId": "6e2bcfda-9aed-4eb5-dfdf-a961b617e999"
      },
      "outputs": [],
      "source": [
        "# Check embeddings\n",
        "print(f\"Number of faces detected: {len(boxes)}\")\n",
        "print(f\"Number of embeddings per face: {len(embeddings[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JC7NI9H15iZ"
      },
      "source": [
        "## Face recognition\n",
        "\n",
        "When using a distance threshold of 0.6, the dlib model obtains an accuracy > 99% on the standard LFW face recognition benchmark.\n",
        "\n",
        "More at: http://dlib.net/dnn_face_recognition_ex.cpp.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "OZQ4nmpjQBPm",
        "outputId": "498071c4-7316-413b-943e-f7865e84c0f2"
      },
      "outputs": [],
      "source": [
        "threshold = 0.6\n",
        "# Load images\n",
        "img1 = Image.open(\"./data/pulp-fiction.jpg\")\n",
        "img2 = Image.open(\"./data/sam-j.jpg\")\n",
        "\n",
        "# Convert image to np.ndarray\n",
        "img1, img2 =  np.array(img1), np.array(img2)\n",
        "\n",
        "# Plot images\n",
        "fig, axes = plt.subplots(1, len([img1, img2]), figsize=(10, 3))\n",
        "for i, image in enumerate([img1, img2]):\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f\"img{i+1}\")\n",
        "    axes[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny_KwVFRXoAT",
        "outputId": "5522516f-0518-4556-b481-6ec124e4c929"
      },
      "outputs": [],
      "source": [
        "# Instantiate dlibFaceProcessor (repeating this line for completeness)\n",
        "face_processor = dlibFaceProcessor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPsV3tNRBOtQ",
        "outputId": "2663d7d3-b332-4608-eb9d-0502805db03c"
      },
      "outputs": [],
      "source": [
        "# Detect faces, get face boxes\n",
        "boxes1 = face_processor.detect_faces(img1)\n",
        "boxes2 = face_processor.detect_faces(img2)\n",
        "# Extract face landmarks\n",
        "shapes1 = face_processor.get_shapes(img1, boxes1)\n",
        "shapes2 = face_processor.get_shapes(img2, boxes2)\n",
        "# Align faces\n",
        "aligned_faces1 = face_processor.align_faces(img1, shapes1)\n",
        "aligned_faces2 = face_processor.align_faces(img2, shapes2)\n",
        "# Extract face embeddings\n",
        "embeddings1 = face_processor.encode_faces(aligned_faces1)\n",
        "embeddings2 = face_processor.encode_faces(aligned_faces2)\n",
        "\n",
        "print(f\"\\nNumber of faces detected on img1: {len(embeddings1)}\")\n",
        "print(f\"Number of faces detected on img2: {len(embeddings2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "rFfmpGXo9jd2",
        "outputId": "e8b23fe7-25d9-4676-a338-aafdf22bd4d8"
      },
      "outputs": [],
      "source": [
        "# Compare the two faces of img1 to the face of the img2\n",
        "\n",
        "for i in range(len(embeddings1)):\n",
        "\n",
        "    distance = euclidean_distance(embeddings1[i], embeddings2[0])\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "    axes[0].imshow(aligned_faces1[i])\n",
        "    axes[0].axis('off')\n",
        "    axes[1].imshow(aligned_faces2[0])\n",
        "    axes[1].axis('off')\n",
        "    if distance > threshold:\n",
        "        fig.suptitle(f'Distance: {distance:.3f} => No Match');\n",
        "    else:\n",
        "        fig.suptitle(f'Distance: {distance:.3f} => Match');"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
